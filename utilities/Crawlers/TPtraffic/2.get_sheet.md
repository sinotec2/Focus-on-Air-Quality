---
layout: default
title:  臺北市交通流量及特性(年度)調查數據檔案之取得
parent: Download Taipei Traffic Data
grand_parent: Crawlers
last_modified_date: 2022-10-13 09:20:27
tags: Crawlers
---

# 臺北市交通流量及特性(年度)調查數據
{: .no_toc }

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>

---

## 背景
- 由於執行方式與成果儲存方式係委託顧問公司於現場或錄影調查，會逐步擴增與更新，如果要進行年度間的比較具挑戰性。
- 各年度、各站點調查結果，係以固定目錄及檔名方式，儲存於內部伺服器，並沒有提供sftp或其他網路服務。而其目錄檔名，按照年度又分別儲存在目錄檔案內。因此有3層下載需求
  1. 所有年度目錄檔([pdf檔](https://www-ws.gov.taipei/001/Upload/456/relfile/0/30323/e53942d0-226c-4ca5-ba43-900b75f2189b.pdf)、[網頁][dlpage])：可以將pdf中連結一一複製另存，也可以將[網頁][dlpage]另存成[html檔案](master:/home/backup/data/ETC/TaipeiVD/htm/all_year.html)，再寫程式解析讀出年度目錄檔之連結。此二者結果雖然略有差異，但在遠端有映射連結，對照到同一個檔案。
  1. 各年度目錄檔
  1. 年度執行結果檔

## 各年度目錄檔
- 所有年度目錄檔中讀出的url範例(url中文碼可在[此](https://www.convertstring.com/zh_TW/EncodeDecode/UrlDecode)轉譯)

```bash
url=( \
http://163.29.251.188/botedata/交通流量/九十一年度/HTML/調查站一覽表.files/sheet001.htm \
http://163.29.251.188/botedata/交通流量/九十二年度/調查站一覽表.files/sheet001.htm \
...
http://163.29.251.188/botedata/交通流量/105年度/105年度臺北市交通流量及特性調查.files/sheet001.htm \
)
```
- 下載批次檔：[get_sheet001.cs](https://github.com/sinotec2/Focus-on-Air-Quality/blob/main/utilities/Crawlers/TPtraffic/get_sheet001.cs)(前半部)
- 分別對15個url都執行：
  1. 以wget取回sheet001.htm檔案
  1. 對sheet001.htm執行解析程式rd_sht1.py，讀取該年度站名。年度之間可能不同。

- sheet001.htm範例。其中站名為href所連結之外部pdf檔案名稱。

```html
...
 <tr height=16 style='height:12.0pt'>
  <td height=16 class=xl26 style='height:12.0pt'><a href="../¸ô¤f/NI001.pdf"
  target="_parent">NI001</a></td>
  <td>¤jª½¾ô~¥_¦w¸ô</td>
 </tr>
 <tr height=16 style='height:12.0pt'>
  <td height=16 class=xl26 style='height:12.0pt'><a href="../¸ô¤f/NI002.pdf"
  target="_parent">NI002</a></td>
  <td>¥«¥Á¤j¹D~Àôªe¥_¸ô</td>
...
```
- [rd_sht1.py]()內容
  - 按照'/'及'.'分割字串後取出站名、另存成文字檔`inter_nam.txt`

```python
#kuang@master /home/backup/data/ETC/TaipeiVD/htm
#$ cat rd_sht1.py
from bs4 import BeautifulSoup
fn=open('sheet001.htm','r')
soup = BeautifulSoup(fn,'html.parser')
fn=open('inter_nam.txt','w')
for i in soup.find_all('a'):
    fn.write(i['href'].split('/')[2].split('.')[0]+'\n')
fn.close()
```

## 年度執行結果之下載
- 批次檔：[get_sheet001.cs](https://github.com/sinotec2/Focus-on-Air-Quality/blob/main/utilities/Crawlers/TPtraffic/get_sheet001.cs)(後半部)

```bash
#kuang@master /home/backup/data/ETC/TaipeiVD/htm
#$ cat get_sheet001.cs
rm sheet*.*
ints=%E8%B7%AF%E5%8F%A3
url=( ... ) #15個url

for m in {12..13};do
n=$(( m - 1 ))
wget ${url[n]} #取得年度目錄
python rd_sht1.py
mv sheet001.htm sht1_$m.htm

for i in $(cat inter_nam.txt);do #對每一個站名(路口)進行迴圈
strA=${url[n]}
strB=`echo ${strA%/*}` #去掉sheet001.htm
strC=`echo ${strB%/*}` #去掉檔案名稱之目錄

# 取得pdf檔案
if [[ $m -eq 12 ||  $m -eq 13  ]] ;then
sht=$i".pdf"
htp=$strC'/'$ints'/'$sht
wget $htp
mv $sht sht3_$m"_$i".pdf #儲存成年度_路口.pdf
FILE=$sht
if [ -f $FILE ]; then rm $FILE;fi

else #其他年度試看看 sheet001~5 可否下載

for j in {1..5};do
sht=sheet00$j".htm"
htp=$strC'/'$ints'/'$i'.files/'$sht
wget $htp
p=`grep \>PHF\< $sht|wc|awkk 1`
if [ $p -eq 0 ]; then rm  $sht;fi
done
sleep 0
sht=`ls -rS sheet00?.htm|tail -n1`
mv $sht sht3_$m"_$i".htm
FILE=sheet00?".htm"
if [ -f $FILE ]; then rm $FILE;fi

fi

done
done
```

## 執行結果
- 所有年度序_站名.htm檔案名稱，儲存於sss.txt
- 解析htm的程式，見[rd_sht3.py](https://github.com/sinotec2/Focus-on-Air-Quality/blob/main/utilities/Crawlers/TPtraffic/rd_sht3.py)及[臺北市交通流量及特性(年度)調查數據檔案之讀取](https://sinotec2.github.io/FAQ/2022/10/13/rd_sht3.html)說明
- sss.txt範例

```bash
kuang@master /home/backup/data/ETC/TaipeiVD/htm
$ head -n3 sss.txt
sht3_12_NI001.txt
sht3_12_NI002.txt
sht3_12_NI003.txt
kuang@master /home/backup/data/ETC/TaipeiVD/htm
$ tail -n3 sss.txt
sht3_9_SI119.htm
sht3_9_SI120.htm
sht3_9_SI121.htm
```
[dlpage]: <https://www.bote.gov.taipei/cp.aspx?n=E0C93DC334AE8028> "臺北市交通管制工程處、交通流量調查資料(PDF下載)"