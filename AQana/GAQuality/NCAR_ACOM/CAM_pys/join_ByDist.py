"""This program was used to calibrate the CAM-chem PM2.5 results with TWEAP station data
usage: python YYYY """
import numpy as np
from pandas import *
from PseudoNetCDF.camxfiles.Memmaps import uamiv
import netCDF4
import matplotlib.pyplot as plt
from scipy.io import FortranFile
import sys, datetime

# input the YYYY
# iyr=int(sys.argv[1])
iyr=2018
#model pm results, bundled by grd04_yd.py, or the following "except" block
fnameO = 'PMf13_12_124_137_83.bin'
year=[i for i in range(2007,2020)]
try:
  with FortranFile(fnameO, 'r') as f:
    pmm = f.read_record(dtype=np.float64)
except:
  pmm=np.zeros(shape=(max(year)-min(year)+1,12,124,137, 83))-1
  for y in year:
    yr=str(y)
    for m in range(12):
      mm='{:02d}'.format(m+1)
      try:
        grd04=uamiv('/nas1/CAM-chem/'+yr+'/'+yr+mm+'/output/'+yr[2:4]+mm+'IC.S.grd04L','r')
        nt,nlay,nrow,ncol=grd04.variables['PM25'].shape
        pmm[y-min(year),m,:nt,:,:]=grd04.variables['PM25'][:,0,:,:]
      except:
        continue
  with FortranFile(fnameO, 'w') as f:
    f.write_record(pmm)
# observation PM2.5 (21 year,13 month, 24 hours, 608 stations
# the bin file was bundled by dfpm.py
fnameO = 'PMf21_13_32_24_608.bin'
with FortranFile(fnameO, 'r') as f:
  pmf = f.read_record(dtype=np.float64)

# the township id and fractions(CMAQ landuse formatted, generated by mk_townNew.py)
nc = netCDF4.Dataset('20160101.ncT','r')
V=[list(filter(lambda x:nc.variables[x].ndim==j, [i for i in nc.variables])) for j in [1,2,3,4]]
nt,nlay,nrow,ncol=nc.variables[V[3][0]].shape

# the township name, ID and stations
df_twnaq=read_csv('town_aqstEnew.csv')
df_ll=read_csv('sta_ll.csv')
intv=1
delH=6
AQD={'Northern':[1,11,12,31,32,33,35],'Central':[17,22,36,37,38,39,40],'Southern':[2,21,41,42,43]}
NCS=[i for i in AQD]
pmm=pmm.reshape(max(year)-min(year)+1,12, 124, 137, 83)
pmf=pmf.reshape(2020-2000+1,13,32,24,608)
sim=np.ones(shape=(2020-2007+1,12,124,372))
#collect station number as a function of station_grids
df_ll['ix_d4']=[int((x-nc.XORIG)/nc.XCELL) for x in df_ll.lcp_x]
df_ll['iy_d4']=[int((y-nc.YORIG)/nc.YCELL) for y in df_ll.lcp_y]
df_ll['JI']=[(j,i) for i,j in zip(df_ll.ix_d4,df_ll.iy_d4)]

#  collect grid  X and Y as functions   of   townIDs
sIYX = {}
land=set()
for v in V[3]:
  if v[0] !='T':continue
  if v == 'T5300': continue
  iv=int(v[1:])
  idx=np.where(nc.variables[v][0,0,:,:]>0)
  iyx=[(idx[0][i],idx[1][i]) for i in range(len(idx[0]))]
  sIYX.update({iv:iyx})
  land=land|set(iyx)
# drop the station outside simulation domain
station=list(set(df_ll.loc[df_ll.JI.map(lambda x:x in land),'JI'])) #list of station ji's
stat2,ns_stat2=[],[] #duplicate stations
for ji in  station:
  n=list(df_ll.JI).count(ji)
  if n > 1:
    if n !=2: sys.exit('n!=2')
    stat2.append(ji)
    ns_stat2.append(list(df_ll.loc[df_ll.JI==ji,'ID']))
stat1=list(set(station)-set(stat2))
station=stat1+stat2 #note the sequence
nst1=len(stat1)
nst2=len(stat2)
nst=nst1+nst2
obs=np.zeros(shape=nst)
ji2st={ji:id for ji,id in zip(df_ll.JI,df_ll.ID) if ji in station}
wts=np.zeros(shape=(nst,nrow,ncol))
# weighting of each land grid to stations, sum=74
for j in range(nrow):
  for i in range(ncol):
    if (j, i) not in land: continue
    if (j, i) in station: continue
    for n in range(nst):
      jj, ii = station[n]
      wts[n,j,i]=900/((jj-j)**2+(ii-i)**2)
    sum_w=np.sum(wts[:,j,i])
    wts[:, j, i]=wts[:,j,i]/sum_w
intv=1
delH=6
AQD={'Northern':[1,11,12,31,32,33,35],'Central':[17,22,36,37,38,39,40],'Southern':[2,21,41,42,43],
     'Yilan':[34],'Huadong':[45,46]}
NCS=[i for i in AQD]
[y_code,s_code,m_code,d_code,h_code,v_code]=[[] for i in range(6)]
for y in [iyr]:#year:
  yy=y-min(year) #UTC
  for m in range(12):
    bdate=datetime.datetime(y,m+1,1)
    for t in range(124):
      tdate=bdate+datetime.timedelta(days=(t*delH+8)/24)
      if tdate>datetime.datetime(2019,6,30):continue
      tdate=tdate.strftime("%Y%m%d%H")
      yr,mn,da,hr=int(tdate[:4]),int(tdate[4:6]),int(tdate[6:8]),int(tdate[8:])
      yo=yr-2000 #LST
      obs[:nst1]=[max(pmf[yo,mn,da,hr,ji2st[ji]],0.) for ji in stat1 ]
      for n in range(nst2):
        a = np.array([pmf[yo,mn,da,hr, ns_stat2[n][i]] for i in range(2)])
        if sum(a)==-2:continue #will use last hour value
        obs[nst1+n]=np.average(a, weights=(a > 0))
      smm = np.zeros(shape=(nrow, ncol))  # (s* / si) x Oi
      for n in range(nst):
        jj, ii = station[n]
        smm[:,:]+=pmm[yy, m, t, :, :]/pmm[yy, m, t, jj, ii]*wts[n,:,:]*obs[n]
      for n in range(nst):
        smm[station[n]]=obs[n]
      for d in NCS[:1]:
        for i in AQD[d]:
          dfa = df_twnaq.loc[df_twnaq.code1 == i].reset_index(drop=True)
          if len(dfa)==0:sys.exit('county not right')
          for ii in dfa.new_code:
            if ii == 0: continue
            dct = 'T' + str(ii)
            if dct not in V[3]: continue
            pp = smm[:, :] * nc.variables[dct][0, 0, :, :]
            idx = np.where(pp > 0)
            y_code.append(y)
            s_code.append(ii)
            m_code.append(m + 1)
            d_code.append(t // 4 + 1)
            h_code.append(t % 4 * 6)
            v_code.append(np.mean([pp[idx[0][k],idx[1][k]] for k in range(len(idx[0]))]))
df=DataFrame({'y':y_code,'s':s_code,'m':m_code,'d':d_code,'h':h_code,'v':v_code})
for s in 'ymdh':
  exec('df.'+s+'=[int(i) for i in df.'+s+']')
ymd=[-1 for i in range(len(df))]
for i in range(len(df)):
  y,m,d,h=df.y[i],df.m[i],df.d[i],df.h[i]
  try:
    ymd[i]=int((datetime.datetime(y,m,d,h)+datetime.timedelta(days=8/24.)).strftime('%Y%m%d'))
  except:
    continue
df['ymd']=ymd
df=df.drop(df.loc[df.ymd<0].index).reset_index(drop=True)
dfv=pivot_table(df,index=['ymd','s'],values='v', aggfunc=np.mean).reset_index()
name={i:j for i,j in zip(df_twnaq.new_code,df_twnaq.Name)}
dfv['name']=[name[i] for i in dfv.s]
dfv.set_index('ymd').to_csv('ymd_s_v'+str(iyr)[2:4]+'.csv')
