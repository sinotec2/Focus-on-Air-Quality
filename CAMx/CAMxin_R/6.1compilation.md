---
layout: default
title: CAMx之編譯
parent: Compilation and Running
grand_parent: CAMx Model System
nav_order: 1
date: 2022-12-02 06:10:00
last_modified_date: 2022-12-02 06:10:10
---

# CAMx之編譯與選項
{: .no_toc }

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>

## 背景

- 自官網下載程式包後、打開、在根目錄即有Makefile可供編譯使用
- 編譯時之選項
  - COMPILER(no default)
    - pgf, pgfomp:
    - ifort, ifortomp
    - absoftomp
    - gfortran, gfortranomp
    - oracle, oracleomp
  - MPI
    - "noMPI" (default)
    - mpich： MPICH(MPICH1, MPICH2), or MPICH3
    - MVAPICH
    - OPENMPI
  - NCF (no default)
    - NCF3
    - NCF4：NCF4_C（with HD5 compression）or NCF4_NC (no compression)
  - IEEE
    - TRUE：invoke IEEE-standard math(default)
    - FALSE：(not recommend)

## COMPILER特性比較

- 此處以pgf, ifort,與gfortran三者的表現進行比較

項目|pgf|ifort|gfortran|
:-:|:-:|:-:|:-:
費用|低|中|無|
lib|單純|複雜|為gcc的一部分|
對語法挑剔度|可|低|高|
OMP執行速度|可|最快|中|
ncf,hd5相容性|可|高|最高|

- ifort、pgi等商業編譯軟體
  - 一般來說，在最新版本狀態，會較gnu軟體還快。因此如果是較舊的商業版本，比起新的gnu就不一定了。
  - 舊版ifort的omp選項是-openmp，新版的選項是-qopenmp
- gnu
  - 雖然是免費軟體系統，但因配合新的OS同步發展，因此反而會有較高的速度表現。相對總體來講，舊的gnu版本會有最慢的速度。
  - gfortran對fortran語法有最高的標準，因此過去認為沒有問題的作法，gfortran都會跳出來(如「引數類型不相符」)
  - omp
    - gfortran的omp選項是-fopenmp，
    - macOS GNU Fortran (Homebrew GCC 9.3.0)版還必須加上程式庫-lgomp
  - GNU Fortran (Homebrew GCC 10.0)必須加上選項，以允許引數類型不相符的呼叫語法"`-w -fallow-argument-mismatch -O2`"

## HDF5, NCF

- NCF選項與前、後處理軟體系統設定有關，如果應用許多netCDF格式之前後處理程式，自然選擇NCF是一合理的系統化作法。
- 輸入檔：NCF選向對傳統uamiv格式會逆向相容，程式會自動判別檔案是什麼格式，並檢查netCDF版本，因此對既有uamiv檔案是OK的。
- 輸出檔：CAMx.in內有選項，可以直接寫出netCDF檔案、或直接進行壓縮，以節省空間。
- NCF及HDF5程式庫的產生可以參考[NC相關程式庫之編譯](https://sinotec2.github.io/Focus-on-Air-Quality/utilities/netCDF/lib_comp/)

## OMP, MPI or both

- MPI或OMP二者為個自獨立的選項，MPI可以做到跨電腦、叢集電腦的平台、需要高效能的內部網路，OMP為則單一電腦、多CPU、在共享內存平台運作。

### MPI基本定義與實現

- 訊息傳遞介面（英語：Message Passing Interface，縮寫MPI）是一個平行計算的應用程式接口（API），常在超級電腦、電腦叢集等非共享內存(non shared memory)環境程序設計。
- MPI訊息傳遞介面,MPI標準定義了核心函式庫的語法和語義，這個函式庫可以被Fortran和C調用構成可移植的信息傳遞程序。
- MPI提供了一個簡單易用的可移植接口，足夠強大到程式設計師可以用它在高級機器上進行進行高性能信息傳遞操作。

### MPI之實現

- Open MPI－ 是自由軟件和開放源碼實現。[1] 走鵑（2008年6月-2009年11月TOP500第一快的超級電腦）[2]及京（2011年6月至今第一快的超級電腦）也使用Open MPI。[3] [4]
- Intel MPI－Intel基於開放源碼的MPICH2與MVAPICH2研發成的MPI。[5]
  - MPICH is a high performance and widely portable implementation of the Message Passing Interface (MPI) standard.
  - MPICH and its derivatives form the most widely used implementations of MPI in the world. They are used exclusively on nine of the top 10 supercomputers (June 2016 ranking), including the world’s fastest supercomputer: Taihu Light.
- Platform MPI－Platform公司收購Scali MPI及HP MPI，研發成Platform MPI。[6]
- OpenMP and shared memory
  - OpenMP（Open Multi-Processing）是一套支持跨平台共享内存方式的多线程并发的编程API，使用C,C++和Fortran语言，可以在大多数的处理器体系和操作系统中运行，包括Solaris, AIX, HP-UX, GNU/Linux, Mac OS X, 和Microsoft Windows。包括一套编译器指令、库和一些能够影响运行行为的环境变量。

## 編譯軟體及結果現況

整理目前工作站各項編譯軟體狀況整理如下所示。

### gfortran/gcc

項目|OS版本|gcc版本|位置|說明
-|-|-|-|-
DEC6工作站<sup>#</sup>|centos6|4.4.7 20120313|/usr/local/bin/gcc|
node03|centos7|4.8.5 20150623|/usr/bin/gcc
DEVP/DEV2|centos7|4.8.5 20150623|/usr/bin/gfortran|
IMacKuang|macOS 10.14.6|Homebrew GCC 11.3.0_2|/usr/local/bin/gfortran|
miniwei|macOS 10.15|Homebrew GCC 11.2.0_3|/usr/local/bin/gfortran

- <sup>#</sup>包括master, node01, node02

### ifort

項目|OS版本|ifort版本|位置|說明
-|-|-|-|-
DEC6工作站<sup>#</sup>|centos6|16.0.1 20151021|/cluster/intel/compilers_and_libraries_2016.1.150|舊版-openmp
DEVP|centos7|19.1.0.166 20191121|/opt/intel_f/compilers_and_libraries_2020.0.166|新版(-qopenmp)
DEV2|centos7| 2021.5.0 20211109|/opt/intel/oneapi/compiler/2022.0.2|新版(-qopenmp)

### netCDF

- netCDF程式庫編譯軟體需與主程式一致
- 在主程式編譯時，也需在Makefile中指定程式庫的路徑(NCF_INST)。

項目|OS版本|nc版本|路徑|說明
-|-|-|-|-
DEC6工作站<sup>#</sup>|centos6|<p>nc 4.6.1 of Dec 20 2018</p><p>nf 4.4.2</p>|/cluster/netcdf|只有ifort版本
node03|centos7|4.4.7 20120313|/opt/netcdf4|只有gcc版本
DEVP/DEV2|centos7|<p>nc 4.7.3 of Jan 23 2020</p><p>nf 4.5.2</p>|<p>/opt/netcdf/netcdf4_gcc</p><p>/opt/netcdf/netcdf4_intel</p>|2各版本都有
IMacKuang|macOS 10.14.6|nc 4.6.2 of Dec 17 2018| /usr/local/NetCDF4|只有gcc版本
miniwei|macOS 10.15|nc 4.7.3 of Feb 19 2020|/usr/local/NetCDF4|只有gcc版本
centos8|centos8|<p>nc 4.7.2 of Jan 15 2020</p><p>nf 4.5.2</p>|/opt/netcdf|只有gcc版本

- <sup>#</sup>包括master, node01, node02


### MPICH

項目|OS版本|nc版本|位置|說明
-|-|-|-|-
DEC6工作站<sup>#</sup>|centos6|3.2 Nov 11 2015|/cluster/mpich|
node03|centos7|3.4.2-icc|/opt/mpich/mpich-3.4.2-icc|非本地編譯
DEVP/DEV2|centos7|<p>mpich3_gcc 3.3.2  Nov 12 2019</p><p> mpich-3.4.2-icc</p>|<p>/opt/mpich/mpich-3.4.2-icc</p><p>/opt/mpich/mpich_gcc</p>|2各版本都有
IMacKuang miniwei|macOS 10.14|-|-|(未安裝)
centos8|centos8|3.3.2  Nov 12 2019|/opt/mpich|只有gcc版本

### openMPI
項目|OS版本|nc版本|位置|說明
-|-|-|-|-
DEC6工作站<sup>#</sup>|centos6|1.10.7, 2.1.1|/cluster/openmpi|
node03|centos7|4.0.2rc3|/opt/openmpi4|
DEVP/DEV2|centos7|4.0.2rc3|/opt/openmpi/openmpi4_gcc|
IMacKuang miniwei|macOS 10.14|4.1.4|/usr/local/Cellar/open-mpi|
centos8|centos8|||

### CAMx程式

項目|OS版本|nc版本|位置|說明
-|-|-|-|-
DEC6工作站<sup>#</sup>|centos6|7.00noMPI.NCF4.ifortomp, noMPI.ifortomp|/cluster/src/CAMx/camx700/|
node03|centos7|CAMx.v7.00, openMPI.NCF4.gfortran, noMPI.gfortranomp, noMPI.ifortomp_cluster|/nas1/camxruns/src/camx700|
DEVP/DEV2|centos7|CAMx.v7.00.MPICH.NCF4.gfortran, noMPI.NCF4.ifortomp, noMPI.ifortomp|same as node03|2各版本都有
IMacKuang miniwei|macOS 10.14|CAMx.v7.00.noMPI.gfortranomp|/Users/camxruns/src/camx700/|(未安裝)
centos8|centos8|CAMx.v7.00.MPICH.NCF4.gfortran, noMPI.NCF4.gfortranomp|/data/camxruns/src/camx700/|

## 執行表現檢討

### (一) 速度之考量
- 目前執行以DEVP及centos8之mpi+gfortran版本最為快速。可能原因
  - ifort較其他編譯器更快速
  - OS與gcc/gfortran的版本皆為最新
  - 即使沒有omp也是最快，可能與omp無法指定NUM_CPUS有關
  - 使用最新的mpich
- (點源排放量誤乘10倍狀況)

工作站|月份|時間(個案日/電腦時間)
-|-|-
node01|(JFM)|46d/15h
node02|(AMJ)|67d/15h
node03|(JAS)|35d/15h
DEVP|(OND)|75d/15h
cent8|(JAJO)|147d/34.75h = 63.5d/15h

### (二) CPU使用率之考量

- omp方案
  - mpi方案可以在命令列指定工作必須使用的CPU個數，但是omp方案則無法指定。過去有NUM_CPUS環境變數可以指定，新的ifort或gfortran理論上會使用到所有系統能夠抓到的CPU，但對目前#CPU>20的架構，似乎不能使用到所有的CPU，因此其效率反而較低。
  - 以DEVP而言，
    - 單一ifortomp在nas1工作，當<<網路忙碌或其他原因>>時最多僅能抓到30個CPU，即使3個ifortomp工作同時運作，也只能用到88%約84個CPU。
    - 在/home(本機硬碟)上工作，最多可以用到85個CPU(among 96 CPUs)，為目前最大使用量。
  - ifortranomp使用CPU的動態情形，如下圖所示。似與排放及濃度有關，當濃度高時，反應速率較快，會啟動較多的CPU，以達到化學平衡，相對排放濃度皆低時，達到平衡的時間較快，計算不需太多。
  - 以CENTOS8/GOMP而言目前能抓到的CPU最多40個，而且同時若有其他GOMP程式進行，會大幅降低執行速度。
- mpi方案
  - 將所有CPU都指定到同一工作，可能因模式格點數的限制，並不能執行，即使能執行，其效率也非最高，有一適合之範圍。
  - 在WRF執行時，此值最多為30個CPU，在CAMx，此值約為24個CPU。
- 停機前點源誤乘了10倍，停機後排放量及濃度都顯著降低，DEVP能夠動用的CPU僅有1/4，然而速度似有顯著提高。


| ![messageImage_1606971684400.jpeg](https://github.com/sinotec2/Focus-on-Air-Quality/blob/main/assets/images/messageImage_1606971684400.jpg?raw=true) |
|:--:|
| <b>ifortranomp使用CPU的動態情形</b>|  


### (三) 記憶體使用率之考量

- 程式記憶體的使用似乎不是使用者可以調控，似為COMPILER自行決定。

item|GOMP方案|IOMP方案|
-|-|-
VIRT|9.070680G|25.4G
RES|6.1g|18.4g
SHR|10612|8544
%MEM|1.6|4

- VIRT: virtue memory
- RES:  Resident Memory Size
- SHR: Shared Memory Size
- %MEM A task's currently used share of available physical memory

## 參考資料與連結

- 訊息傳遞介面 wiki, https://zh.wikipedia.org/wiki/訊息傳遞介面
- MPICH https://www.mpich.org/
- Linux環境進程間通信（五）: 共享內存（上）, https://www.itdaan.com/tw/c699361da70b1e14f4f6055dbf5ca9a6
- OpenMP, https://zh.wikipedia.org/wiki/OpenMP
- Shared Memory Programming with OpenMP, https://materials.prace-ri.eu/470/2/OpenMPintroductionSMPWOE15.pdf
- Shared Memory and OpenMP Basics, http://shodor.org/~bplist/bwi/openmp.html
