# Tuesday, August 29, 2023 NLP

## Definition

### amazon

- [什麼是自然語言處理 (NLP)？](https://aws.amazon.com/tw/what-is/nlp/)
  > 自然語言處理 (NLP) 是一種機器學習技術，讓電腦能夠解譯、操縱及理解人類語言。如今，組織擁有來自各種通訊管道的大量語音和文字資料，例如電子郵件、簡訊、社交媒體新聞摘要、影片、音訊等。他們使用 NLP 軟體來自動處理此資料，分析訊息中的意圖或情緒，並即時回應人類通訊。
  - 為什麼 NLP 很重要？
  - 什麼是企業的 NLP 使用案例？
  - NLP 如何運作？
  - 什麼是 NLP 任務？
  - 自然語言處理採用哪些方法？
  > 針對想要在其業務中建立標準 NLP 解決方案的客戶，Amazon SageMaker 可透過全受管基礎設施、工具和工作流程，輕鬆準備資料，以及建置、訓練和部署機器學習模型，包括適用於商業分析師的無程式碼服務。藉助 Amazon SageMaker 上的 *Hugging Face*，您可以部署和微調來自 *Hugging Face* 的預先訓練模型，*Hugging Face* 是稱為 Transformers 的自然語言處理 (NLP) 模型的開放原始碼供應商，將設定和使用這些 NLP 模型所需的時間從數週縮短至幾分鐘。

立即建立 AWS 帳戶，開始使用自然語言處理 (NLP)。

## Hugging Face

- The AI community building the future.
- The platform where the machine learning community collaborates on models, datasets, and applications.
- If you need to create a repo from the command line (skip if you created a repo from the website)
- HuggingGPT爆紅，Hugging Face又是什麼？它正在拆掉OpenAI的圍牆，要當AI界的Github、[36Kr 發表於 2023年4月30日 16:00 電腦王->](https://www.techbang.com/posts/105484-hugginggpt-is-on-fire-what-is-hugging-face-hugging-face-a-2)
  >  
- Hugging Face 架構與三大神器 by [大魔術熊貓工程師2022-09-17 20:35:25@ithelp.ithome](https://ithelp.ithome.com.tw/articles/10291757)
- 

### Getting started

- with our git and git-lfs interface

```bash
pip install huggingface_hub
#You already have it if you installed transformers or datasets

huggingface-cli login

# Log in using a token from huggingface.co/settings/tokens
# Create a model or dataset repo from the CLI if needed
huggingface-cli repo create repo_name --type {model, dataset, space}
```

### Clone your model or dataset locally

```bash
#Make sure you have git-lfs installed
#(https://git-lfs.github.com)
git lfs install
git clone https://huggingface.co/username/repo_name
```

- Then add, commit and push any file you want, including larges files

```bash
# save files via `.save_pretrained()` or move them here
git add .
git commit -m "commit from $USER"
git push
```

- In most cases, if you're using one of the compatible libraries, your repo will then be accessible from code, through its identifier: username/repo_name

For example for a transformers model, anyone can load it with:

```python
tokenizer = AutoTokenizer.from_pretrained("username/repo_name")
model = AutoModel.from_pretrained("username/repo_name")
```

## Pile

- The Pile: An 800GB Dataset of Diverse Text for Language Modeling @[eleuther(2020)](https://pile.eleuther.ai/)
- `https://the-eye.eu/public/AI/pile_preliminary_components`目錄已經不存在了，改成
- 